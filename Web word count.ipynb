{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk#natual language tool kit is the one of the most using library\n",
    "nltk.download()#to download tha packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we will learn how to identify what the web page is about \n",
    "#using NLTK in Python.\n",
    "\n",
    "import urllib.request\n",
    "response =  urllib.request.urlopen('https://en.wikipedia.org/wiki/SpaceX')\n",
    "html = response.read()\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to pull the data\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html,'html5lib')\n",
    "text = soup.get_text(strip = True)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to split the data into a seperate words:\n",
    "\n",
    "tokens = [t for t in text.split()]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting the number of frequencies for each words:\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "sr= stopwords.words('english')\n",
    "clean_tokens = tokens[:]\n",
    "for token in tokens:\n",
    "    if token in stopwords.words('english'):\n",
    "        \n",
    "        clean_tokens.remove(token)\n",
    "freq = nltk.FreqDist(clean_tokens)\n",
    "for key,val in freq.items():\n",
    "    print(str(key) + ':' + str(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to plot the frequencies of each words:\n",
    "\n",
    "freq.plot(20, cumulative=False)#to check the frequency of the top 20 words in the website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to pull the data\n",
    "\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with urllib.request.urlopen(\"https://timesofindia.indiatimes.com/entertainment/hindi/bollywood/news/u-p-police-to-file-fir-against-kanika-kapoor-who-has-been-tested-positive-for-covid-19/articleshow/74736342.cms\") as url:\n",
    "    html = url.read()\n",
    "    soup = BeautifulSoup(html)\n",
    "\n",
    "# kill all script and style elements\n",
    "for script in soup([\"script\", \"style\"]):\n",
    "    script.extract()    # rip it out\n",
    "\n",
    "# get text\n",
    "text = soup.get_text()\n",
    "\n",
    "# break into lines and remove leading and trailing space on each\n",
    "lines = (line.strip() for line in text.splitlines())\n",
    "# break multi-headlines into a line each\n",
    "chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "# drop blank lines\n",
    "text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to split the data into a seperate words:\n",
    "\n",
    "tokens = [t for t in text.split()]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting the number of frequencies for each words:\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "sr= stopwords.words('english')\n",
    "clean_tokens = tokens[:]\n",
    "for token in tokens:\n",
    "    if token in stopwords.words('english'):\n",
    "        \n",
    "        clean_tokens.remove(token)\n",
    "freq = nltk.FreqDist(clean_tokens)\n",
    "for key,val in freq.items():\n",
    "    print(str(key) + ':' + str(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to plot the frequencies of each words:\n",
    "\n",
    "freq.plot(20, cumulative=False)#to check the frequency of the top 20 words in the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
